{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c7787aa-2226-4f01-8958-f8c030683b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "import random \n",
    "import time\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np \n",
    "from torch.utils.data import TensorDataset,Subset\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28758369-f8ec-491a-93c2-50a5b1c1ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ffde6a-1a79-4eb5-93bb-3442bd371783",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14544874-9078-4b0a-ac83-efa3499d88cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38170ab8-0515-4eb3-aeb3-c92b23b031c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1784719b-b17b-4a98-8d0e-1e38e3a0b058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef65769-99e1-479c-9808-4820ea83a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d450c8-56e7-4937-b47d-c54d705adf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18e6de1f-899a-49b5-b4e2-5e8f0326b20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_tokenize(text):\n",
    "  tokenizer = TweetTokenizer()\n",
    "  tokens = tokenizer.tokenize(text.lower())\n",
    "  tokens = [token for token in tokens]\n",
    "\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6163b46-d155-4ca8-abdc-acfbcab05f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(tokens):\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    processed_text = \" \".join(tokens)\n",
    "    processed_text = \" \".join(processed_text.split())\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdb58ce8-f18b-4702-bd13-69d0c0e5a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cyber-troll.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b4c7f44-7b20-4e82-89f4-05e7d54d986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['content'].apply(tweet_tokenize)\n",
    "data['content'] = data['content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fce3b6d-5b9f-4fec-81e4-ea79f0fd2606",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.sample(n=1000, random_state=42)\n",
    "\n",
    "remaining_data = data.drop(train_data.index)\n",
    "\n",
    "test_data = remaining_data.sample(n=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde9fd36-3964-4fd2-bd7e-1c5f95514722",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.head())\n",
    "\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2dad4a4-68db-4c37-bc2c-0874d1932787",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = train_data.content.values\n",
    "labels = train_data.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "502f611b-949b-44bb-9de4-03ace513f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e19576-9163-41b8-b0f0-8956ab74786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "  \n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = max_length,           # Pad & truncate all sentences.\n",
    "                        padding = 'max_length',\n",
    "                        truncation = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e80be65-6919-4327-87b0-b7b33880c836",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16 \n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "#helper function to get train and val data loaders for each fold \n",
    "def get_data_loaders(dataset,train_indexes,val_indexes):\n",
    "    train_tensor = Subset(dataset,train_indexes)\n",
    "    val_tensor = Subset(dataset,val_indexes)\n",
    "    train_dataloader = DataLoader(\n",
    "            train_tensor, \n",
    "            sampler = RandomSampler(train_tensor), \n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "            val_tensor, \n",
    "            sampler = SequentialSampler(val_tensor), \n",
    "            batch_size = batch_size \n",
    "        )\n",
    "    return train_dataloader,val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "257115ae-70d7-4666-a46b-61c5144a12a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "904da8cc-d606-4099-88fd-becbada0e0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = test_data.content.values\n",
    "input_ids = []\n",
    "attention_masks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77a2f10d-912c-44b2-af09-0ec9d6676537",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in sentences:\n",
    "\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = max_length,           # Pad & truncate all sentences.\n",
    "                        padding = 'max_length',\n",
    "                        truncation = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "# Set the batch size.  \n",
    "batch_size = 16  \n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff936818-bab3-4218-bc72-9a7095f7c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertConfig\n",
    "\n",
    "def get_bert_model():\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "      \"bert-base-uncased\", \n",
    "      num_labels = 2,           \n",
    "      output_attentions = False, \n",
    "      output_hidden_states = False, \n",
    "    )\n",
    "    # Tell pytorch to run this model on the GPU.\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    else:\n",
    "        model.cpu()\n",
    "    #model.gpu()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0cd2d7b-b7e8-443f-809d-b35fd07f24f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f379ef6-5355-4f25-957b-e06b2547c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7e12e9c-ef81-4de0-9791-3cf2e34988be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 1000\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8844d072-530c-4509-9598-1f138b36fd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_folds = 10\n",
    "current_fold = 0\n",
    "all_folds_preds = []\n",
    "epochs = 20\n",
    "fold=StratifiedKFold(n_splits=total_folds, shuffle=True, random_state=seed_val)\n",
    "\n",
    "training_stats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c371198-0fc2-4b09-bb10-dfe1fa895ec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "#for each fold..\n",
    "for train_index, test_index in fold.split(train_data,train_data['label']):\n",
    "    model = get_bert_model()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),lr = 5e-5,eps = 1e-8)\n",
    "    current_fold = current_fold+1\n",
    "    train_dataloader,validation_dataloader = get_data_loaders(dataset,train_index,test_index)\n",
    "    print(\"\")\n",
    "    print('================= Fold {:} / {:} ================='.format(current_fold,total_folds))\n",
    "    # For each epoch...\n",
    "    for epoch_i in range(0, epochs):\n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "\n",
    "        # Perform one full pass over the training set.\n",
    "\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        # Measure how long the training epoch takes.\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Reset the total loss for this epoch.\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            model.zero_grad()        \n",
    "\n",
    "            outputs = model(b_input_ids, \n",
    "                              token_type_ids=None, \n",
    "                              attention_mask=b_input_mask, \n",
    "                              labels=b_labels)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate the gradients.\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            #update weights\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "\n",
    "        # Measure how long this epoch took.\n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "\n",
    "        # ========================================\n",
    "        #               Validation\n",
    "        # ========================================\n",
    "        # After the completion of each training epoch, measure our performance on\n",
    "        # our validation set.\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Put the model in evaluation mode--the dropout layers behave differently\n",
    "        # during evaluation.\n",
    "        model.eval()\n",
    "\n",
    "        # Tracking variables \n",
    "        total_f1_score = 0\n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in validation_dataloader:\n",
    "\n",
    "\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            with torch.no_grad():        \n",
    "                outputs = model(b_input_ids, \n",
    "                                        token_type_ids=None, \n",
    "                                        attention_mask=b_input_mask,\n",
    "                                        labels=b_labels)\n",
    "                loss = outputs.loss\n",
    "                logits = outputs.logits\n",
    "\n",
    "            # Accumulate the validation loss.\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Calculate the accuracy for this batch of test sentences, and\n",
    "            # accumulate it over all batches.\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "            total_f1_score += f1_score(np.argmax(logits,axis=1),label_ids)\n",
    "\n",
    "        # Report the final accuracy and f1_score for this validation run.\n",
    "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "        \n",
    "        avg_f1_score = total_f1_score / len(validation_dataloader)\n",
    "        print(\"  F1_score: {0:.2f}\".format(avg_f1_score))\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "        # Measure how long the validation run took.\n",
    "        validation_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "        print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "        # Record all statistics from this epoch.\n",
    "        training_stats.append(\n",
    "          {\n",
    "              'epoch': epoch_i + 1,\n",
    "              'Training Loss': avg_train_loss,\n",
    "              'Valid. Loss': avg_val_loss,\n",
    "              'Valid. Accur.': avg_val_accuracy,\n",
    "              'f1_score' : avg_f1_score,\n",
    "              'Training Time': training_time,\n",
    "              'Validation Time': validation_time,\n",
    "              'fold' : current_fold\n",
    "              \n",
    "          }\n",
    "        )\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "\n",
    "    # ========================================\n",
    "    # Predicting and saving predictions for all folds\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"now predicting for this fold\")\n",
    "\n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "    # Tracking variables \n",
    "    predictions  = []\n",
    "    # Predict \n",
    "    for batch in prediction_dataloader:\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask = batch\n",
    "        # speeding up prediction\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions\n",
    "            outputs = model(b_input_ids, token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "        predictions.append(logits)\n",
    "\n",
    "    stack = np.vstack(predictions)\n",
    "    # final_preds = F.softmax(torch.from_numpy(stack))[:,1].numpy()\n",
    "\n",
    "    final_preds = F.softmax(torch.from_numpy(stack), dim=1)[:, 1].numpy()\n",
    "    all_folds_preds.append(final_preds)\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749618e9-0e2c-41d8-b9be-6c884adf9fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision', 2)\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "df_stats = df_stats.set_index('fold')\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df22a62-f3e4-4d38-8ceb-1dbdf135d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f265ae4-6a97-4499-aaa8-26572e5b5da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = np.mean(all_folds_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0526d8d5-0056-4b9c-80e1-33af07556acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bba2006-bb8d-4e5c-9875-cdb791224833",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_folds_preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7454009-1ead-4913-84f3-1ee47ddec868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "binary_predictions = (final_preds > 0.5).astype(int)\n",
    "\n",
    "labels_true = test_data.label.values\n",
    "\n",
    "accuracy = accuracy_score(labels_true, binary_predictions)\n",
    "f1 = f1_score(labels_true, binary_predictions)\n",
    "recall = recall_score(labels_true, binary_predictions)\n",
    "precision = precision_score(labels_true, binary_predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "test_data['predictions'] = binary_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372736a8-753d-4070-a2f8-dc2e7337f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './bert_save_model/'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving the trained model %s\"% output_dir)\n",
    "\n",
    "model.save_pretrained(output_dir)\n",
    "\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
