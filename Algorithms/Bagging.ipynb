{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Maricondi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../cyber-troll.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20001, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(tokens):\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    processed_text = \" \".join(tokens) \n",
    "    processed_text = \" \".join(processed_text.split())\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_tokenize(texto):\n",
    "  tokenizer = TweetTokenizer()\n",
    "  tokens = tokenizer.tokenize(texto.lower())\n",
    "  tokens = [token for token in tokens]\n",
    "\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    tp = sum((y_true == 1) & (y_pred == 1))\n",
    "    tn = sum((y_true == 0) & (y_pred == 0))\n",
    "    fp = sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=2000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maricondi\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=tweet_tokenize, sublinear_tf=True, smooth_idf=True)\n",
    "X_train = vectorizer.fit_transform(train_data['content'])\n",
    "y_train = train_data['label']\n",
    "X_test = vectorizer.transform(test_data['content'])\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_classifier = ExtraTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_classifier = BaggingClassifier(estimator=base_classifier, n_estimators=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do fold: 0.9250416435313714\n",
      "Precisão do fold: 0.902127659574468\n",
      "Revocação do fold: 0.905982905982906\n",
      "F1-score do fold: 0.9040511727078892\n",
      "-------------------------------------\n",
      "Acurácia do fold: 0.9266666666666666\n",
      "Precisão do fold: 0.9214814814814815\n",
      "Revocação do fold: 0.8873038516405135\n",
      "F1-score do fold: 0.9040697674418604\n",
      "-------------------------------------\n",
      "Acurácia do fold: 0.9316666666666666\n",
      "Precisão do fold: 0.9200581395348837\n",
      "Revocação do fold: 0.9029957203994294\n",
      "F1-score do fold: 0.9114470842332614\n",
      "-------------------------------------\n",
      "Acurácia do fold: 0.9222222222222223\n",
      "Precisão do fold: 0.914327917282127\n",
      "Revocação do fold: 0.8830242510699001\n",
      "F1-score do fold: 0.8984034833091438\n",
      "-------------------------------------\n",
      "Acurácia do fold: 0.9338888888888889\n",
      "Precisão do fold: 0.924198250728863\n",
      "Revocação do fold: 0.9044222539229672\n",
      "F1-score do fold: 0.9142033165104543\n",
      "-------------------------------------\n",
      "Acurácia do fold: 0.9355555555555556\n",
      "Precisão do fold: 0.9172610556348074\n",
      "Revocação do fold: 0.9172610556348074\n",
      "F1-score do fold: 0.9172610556348074\n",
      "-------------------------------------\n",
      "Acurácia do fold: 0.9316666666666666\n",
      "Precisão do fold: 0.9083215796897038\n",
      "Revocação do fold: 0.9173789173789174\n",
      "F1-score do fold: 0.9128277817150957\n",
      "-------------------------------------\n",
      "Acurácia do fold: 0.9333333333333333\n",
      "Precisão do fold: 0.9019337016574586\n",
      "Revocação do fold: 0.9301994301994302\n",
      "F1-score do fold: 0.9158485273492286\n",
      "-------------------------------------\n",
      "Acurácia do fold: 0.9338888888888889\n",
      "Precisão do fold: 0.9170243204577968\n",
      "Revocação do fold: 0.9131054131054132\n",
      "F1-score do fold: 0.9150606709493219\n",
      "-------------------------------------\n",
      "Acurácia do fold: 0.9211111111111111\n",
      "Precisão do fold: 0.9057971014492754\n",
      "Revocação do fold: 0.8903133903133903\n",
      "F1-score do fold: 0.8979885057471264\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    bagging_classifier.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    val_predictions = bagging_classifier.predict(X_val_fold)\n",
    "\n",
    "    accuracy, precision, recall, f1 = calculate_metrics(y_val_fold.values, val_predictions)\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    print(f'Acurácia do fold: {accuracy}')\n",
    "    print(f'Precisão do fold: {precision}')\n",
    "    print(f'Revocação do fold: {recall}')\n",
    "    print(f'F1-score do fold: {f1}')\n",
    "    print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 0.9295041643531372\n",
      "precisão média: 0.9132531207490866\n",
      "revocação média: 0.9051987189647674\n",
      "F1 média: 0.9091161365598188\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = np.mean(accuracies)\n",
    "print(f'Acurácia média: {mean_accuracy}')\n",
    "mean_precision = np.mean(precisions)\n",
    "print(f'precisão média: {mean_precision}')\n",
    "mean_recall = np.mean(recalls)\n",
    "print(f'revocação média: {mean_recall}')\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "print(f'F1 média: {mean_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = bagging_classifier.predict(X_test)\n",
    "\n",
    "test_accuracy, test_precision, test_recall, test_f1 = calculate_metrics(y_test.values, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no conjunto de teste: 0.932\n",
      "Precisão no conjunto de teste: 0.9178082191780822\n",
      "Revocação no conjunto de teste: 0.9132589838909542\n",
      "F1-score no conjunto de teste: 0.9155279503105591\n"
     ]
    }
   ],
   "source": [
    "print(f'Acurácia no conjunto de teste: {test_accuracy}')\n",
    "print(f'Precisão no conjunto de teste: {test_precision}')\n",
    "print(f'Revocação no conjunto de teste: {test_recall}')\n",
    "print(f'F1-score no conjunto de teste: {test_f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
